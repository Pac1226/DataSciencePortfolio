{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad64fab3-c272-411b-b0fe-89234b5a48c2",
   "metadata": {},
   "source": [
    "# Machine Learning Models for Algorithmic Trading #\n",
    "\n",
    "This is a machine learning template that can be adapted to build unique algorithmic trading bots. \n",
    "\n",
    "It aggregates data from any three sources and prepares the data using \"Train, Test, Split\", \"RandomOversampler\", and \"StandardScaler.\" \n",
    "\n",
    "Finally it runs the cleaned data through three machine learning models:\n",
    "\n",
    "* Logistic Regression\n",
    "* Random Forest Classification\n",
    "* Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "537625ba-5dfc-4f10-a795-83b1eb52a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Imports the machine learning modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "# Imports the data reporting modules\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556707bf-0108-4695-a5a4-8c2b24f722be",
   "metadata": {},
   "source": [
    "### Step 1: Data Aggregation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a016d8a-bb3d-4a9d-abe9-29b7c95eb1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the CSV Path for the three (3) antecedent models\n",
    "# Load the Oil Returns Data into \"csv_path_1\" \n",
    "csv_path_1 = Path(\"./live_data/fundamental_output.csv\")\n",
    "csv_path_2 = Path(\"./live_data/macro_output.csv\")\n",
    "csv_path_3 = Path(\"./live_data/technical_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "128870c9-c9b5-45c1-a753-e1636d8b10a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1 linear</th>\n",
       "      <th>x_2 linear</th>\n",
       "      <th>x_3 linear</th>\n",
       "      <th>x_1 exponential</th>\n",
       "      <th>x_2 exponential</th>\n",
       "      <th>x_3 exponential</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Strategy Returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-01</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-02</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-03</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-05</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-28</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-30</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-31</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>461 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x_1 linear  x_2 linear  x_3 linear  x_1 exponential  \\\n",
       "Date                                                              \n",
       "2020-06-01          -1           1           1                1   \n",
       "2020-06-02           1           1           1                1   \n",
       "2020-06-03          -1           1           1                1   \n",
       "2020-06-04           1           1           1                1   \n",
       "2020-06-05           1           1           1                1   \n",
       "...                ...         ...         ...              ...   \n",
       "2022-03-25           1           1           1                1   \n",
       "2022-03-28          -1           1           1                1   \n",
       "2022-03-29           1           1           1                1   \n",
       "2022-03-30           1           1           1                1   \n",
       "2022-03-31          -1           1           1                1   \n",
       "\n",
       "            x_2 exponential  x_3 exponential  Signal  Strategy Returns  \n",
       "Date                                                                    \n",
       "2020-06-01                1                1    -1.0               NaN  \n",
       "2020-06-02                1                1     1.0              -1.0  \n",
       "2020-06-03                1                1    -1.0              -1.0  \n",
       "2020-06-04                1                1     1.0              -1.0  \n",
       "2020-06-05                1                1     1.0               1.0  \n",
       "...                     ...              ...     ...               ...  \n",
       "2022-03-25                1                1     1.0              -1.0  \n",
       "2022-03-28                1                1    -1.0              -1.0  \n",
       "2022-03-29                1                1     1.0              -1.0  \n",
       "2022-03-30                1                1     1.0               1.0  \n",
       "2022-03-31                1                1    -1.0              -1.0  \n",
       "\n",
       "[461 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads the CSV files\n",
    "model_one_output = pd.read_csv(csv_path_1, index_col=\"Date\", parse_dates=True, infer_datetime_format=True)\n",
    "model_two_output = pd.read_csv(csv_path_2, index_col=\"Date\", parse_dates=True, infer_datetime_format=True)\n",
    "model_three_output = pd.read_csv(csv_path_3, index_col=\"Date\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "# Concatenates all three into a single DataFrame (called \"model_inputs\")\n",
    "model_inputs = pd.concat([model_one_output, model_two_output, model_three_output],  axis= \"columns\", join=\"inner\")\n",
    "\n",
    "# Renames columns to generic variables\n",
    "column_names = [\"x_1 linear\", \"x_2 linear\", \"x_3 linear\"]\n",
    "model_inputs.columns = column_names\n",
    "\n",
    "# Creates three (3) additional inputs that squares the  original data\n",
    "model_inputs[\"x_1 exponential\"] = model_inputs[\"x_1 linear\"] * model_inputs[\"x_1 linear\"]\n",
    "model_inputs[\"x_2 exponential\"] = model_inputs[\"x_2 linear\"] * model_inputs[\"x_2 linear\"]\n",
    "model_inputs[\"x_3 exponential\"] = model_inputs[\"x_3 linear\"] * model_inputs[\"x_3 linear\"]\n",
    "\n",
    "# Initializes the new Signal column\n",
    "model_inputs['Signal'] = 0.0\n",
    "\n",
    "# When Actual Returns (\"x_1 linear\") are greater than or equal to 0, generates signal to buy stock long\n",
    "model_inputs.loc[(model_inputs[\"x_1 linear\"] >= 1), 'Signal'] = 1\n",
    "\n",
    "# When Actual Returns (\"x_1 linear\") are less than 1, generates signal to sell oil\n",
    "model_inputs.loc[(model_inputs[\"x_1 linear\"] < 1), 'Signal'] = -1\n",
    "\n",
    "# Calculates the strategy returns and add them to the signals_df DataFrame\n",
    "model_inputs['Strategy Returns'] = model_inputs['x_1 linear'] * model_inputs['Signal'].shift()\n",
    "\n",
    "# Prints cleaned DataFrame\n",
    "model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae0bb74-5160-4ce2-967a-f751ae7939d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2: Data Preparation: \"Train, Test, Split\", \"Oversampler\" & Standard Scaler ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84579e7d-e857-4907-b8b1-f94f04c93c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    347\n",
       "-1.0    114\n",
       "Name: Signal, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates the target set selecting the Signal column and assiging it to y\n",
    "y = model_inputs[\"Signal\"]\n",
    "\n",
    "# Creates the model inputs by dropping Signal & Strategy Returns columns and assigning it to X\n",
    "X = model_inputs.drop(columns=[\"Signal\", \"Strategy Returns\"])\n",
    "\n",
    "# Splits the data using train_test_split and assigns a random_state of 1 to the function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Checks the y values to determine if oversampling is needed\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5ecf22f-2fc5-4d24-ab74-759798061cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    256\n",
       "-1.0    256\n",
       "Name: Signal, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiates the random oversampler model with a random_state parameter of 1\n",
    "random_oversampler = RandomOverSampler(random_state=1)\n",
    "\n",
    "# Fits the original training data to the random_oversampler model\n",
    "X_resampled, y_resampled = random_oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Checks the resamped y values\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03dd1c23-1154-4269-a782-56c31417e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Applys the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_resampled)\n",
    "\n",
    "# Transforms the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_resampled)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6ae3d8-a55a-4bcd-9663-1f24cda8af73",
   "metadata": {},
   "source": [
    "### Model 1: Logistic Regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f140727f-9afc-4ec7-854e-9db024802889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0     1.0000    1.0000    1.0000        25\n",
      "         1.0     1.0000    1.0000    1.0000        91\n",
      "\n",
      "    accuracy                         1.0000       116\n",
      "   macro avg     1.0000    1.0000    1.0000       116\n",
      "weighted avg     1.0000    1.0000    1.0000       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creates a LogisticRegression model and trains it on the X_train_scaled and y_resampled\n",
    "regression_model = LogisticRegression()\n",
    "regression_model.fit(X_train_scaled, y_resampled)\n",
    "\n",
    "# Uses the model you trained to predict using X_test_scaled\n",
    "y_pred = regression_model.predict(X_test_scaled)\n",
    "\n",
    "# Creates a classification report to evaluate performance and saves it\n",
    "regression_testing_report = classification_report(y_test, y_pred, digits=4)\n",
    "\n",
    "# Prints out a classification report to evaluate performance\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0745391a-4b3f-4483-a836-a2a8295427ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model 2: Random Forest Classification ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dd6a91a-6889-4e61-a22b-090cafb575d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0     1.0000    1.0000    1.0000        25\n",
      "         1.0     1.0000    1.0000    1.0000        91\n",
      "\n",
      "    accuracy                         1.0000       116\n",
      "   macro avg     1.0000    1.0000    1.0000       116\n",
      "weighted avg     1.0000    1.0000    1.0000       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creates a RandomForestClassifier model and trains it on the X_train_scaled\n",
    "forest_model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Uses the model you trained to predict using X_test_scaled\n",
    "forest_model.fit(X_train_scaled, y_resampled)\n",
    "y_pred = forest_model.predict(X_test_scaled)\n",
    "\n",
    "# Creates a classification report to evaluate performance and saves it\n",
    "forest_testing_report = classification_report(y_test, y_pred, digits=4)\n",
    "\n",
    "# Prints out a classification report to evaluate performance\n",
    "print(forest_testing_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fadff62-0a50-4a92-ba7c-68bada2b6a31",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model 3: Suppor Vector Classification (SVC) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c13de3fe-a771-4bd1-b405-22d9b13d760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0     1.0000    1.0000    1.0000        25\n",
      "         1.0     1.0000    1.0000    1.0000        91\n",
      "\n",
      "    accuracy                         1.0000       116\n",
      "   macro avg     1.0000    1.0000    1.0000       116\n",
      "weighted avg     1.0000    1.0000    1.0000       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# From SVM, instantiates SVC classifier model instance\n",
    "svm_model = svm.SVC()\n",
    " \n",
    "# Fits the model to the data using the training data\n",
    "svm_model = svm_model.fit(X_train_scaled, y_resampled)\n",
    " \n",
    "# Uses the testing data to make the model predictions\n",
    "svm_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Creates a classification report to evaluate performance and saves it\n",
    "svm_testing_report = classification_report(y_test, svm_pred, digits=4)\n",
    "\n",
    "# Print the classification report\n",
    "print(svm_testing_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aacd10-83e1-4544-af31-aa53f4234272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
